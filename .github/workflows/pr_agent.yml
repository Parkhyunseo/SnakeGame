name: PR-Agent (Windows self-hosted + Ollama EXAONE)

on:
  pull_request:
    types: [opened, reopened, ready_for_review, synchronize]
    paths: ['**/*.py']
  issue_comment:
    types: [created, edited]

jobs:
  review:
    runs-on: [self-hosted, Windows]
    defaults:
      run:
        shell: powershell
    permissions:
      issues: write
      pull-requests: write
      contents: write

    steps:
      - uses: actions/checkout@v4

      # 1) Ollama 컨테이너 기동(컨테이너명이 reviewOllama인 상황 반영)
      - name: Ensure Ollama (reviewOllama) is running
        run: |
          $running = docker ps --format '{{.Names}}' | Select-String -Pattern '^reviewOllama$'
          if (-not $running) {
            $exists = docker ps -a --format '{{.Names}}' | Select-String -Pattern '^reviewOllama$'
            if (-not $exists) {
              docker run -d --name reviewOllama --restart unless-stopped `
                -p 11434:11434 `
                -e OLLAMA_CONTEXT_LENGTH=8192 `
                -v ollama_models:/root/.ollama `
                ollama/ollama:latest | Out-Null
            } else {
              docker start reviewOllama | Out-Null
            }
          }
          # 로컬에서 바로 응답 체크
          Invoke-RestMethod http://localhost:11434/api/tags -Method GET | Out-Null

      # 2) EXAONE 모델 준비
      - name: Pull EXAONE 3.5 model
        run: |
          Invoke-RestMethod http://localhost:11434/api/pull -Method POST -ContentType 'application/json' `
            -Body '{"name":"exaone3.5:7.8b"}' | Out-Null
          $ok = $false
          for ($i=0; $i -lt 60; $i++) {
            try {
              $resp = Invoke-RestMethod http://localhost:11434/api/tags -Method GET
              if ($resp.models.name -contains 'exaone3.5:7.8b') { $ok = $true; break }
            } catch {}
            Start-Sleep 5
          }
          if (-not $ok) { throw "exaone3.5:7.8b 모델이 5분 내 준비되지 않았습니다." }

      # 3) 컨테이너에서 '호스트(Ollama) 접근' 스모크 테스트
      - name: Smoke test (container -> host.docker.internal)
        run: |
          docker run --rm curlimages/curl -fsS http://host.docker.internal:11434/api/tags

      # 4) PR-Agent 리뷰 실행 (OpenAI 호환 모드로 Ollama 호출)
      - name: PR-Agent review
        env:
          PR_URL: ${{ github.event.pull_request.html_url }}
        run: |
          $envs = @(
            "OPENAI__API_BASE=http://host.docker.internal:11434/v1",
            "OPENAI__KEY=dummy",
            "CONFIG__ACTIVE_PROVIDER=openai",
            "CONFIG__MODEL=exaone3.5:7.8b",
            "CONFIG__CUSTOM_MODEL_MAX_TOKENS=8000",
            "CONFIG__FALLBACK_MODELS=[]",
            "CONFIG__LOG_LEVEL=DEBUG",
            "GITHUB__USER_TOKEN=${{ secrets.GITHUB_TOKEN }}"
          )
      
          $args = @("run","--rm")
          foreach ($e in $envs) { $args += @("-e",$e) }
          $args += @("codiumai/pr-agent:latest","--pr_url","$Env:PR_URL","review")
      
          & docker @args


      # 5) (선택) PR 설명도 생성
      - name: PR-Agent describe (optional)
        if: success()
        env:
          PR_URL: ${{ github.event.pull_request.html_url }}
        run: |
          $envs = @(
            "OPENAI__API_BASE=http://host.docker.internal:11434/v1",
            "OPENAI__KEY=dummy",
            "CONFIG__ACTIVE_PROVIDER=openai",
            "CONFIG__MODEL=exaone3.5:7.8b",
            "CONFIG__CUSTOM_MODEL_MAX_TOKENS=8000",
            "CONFIG__FALLBACK_MODELS=[]",
            "CONFIG__LOG_LEVEL=DEBUG",
            "GITHUB__USER_TOKEN=${{ secrets.GITHUB_TOKEN }}"
          )
          $args = @("run","--rm")
          foreach ($e in $envs) { $args += @("-e",$e) }
          $args += @("codiumai/pr-agent:latest","--pr_url","$Env:PR_URL","describe")
          & docker @args
